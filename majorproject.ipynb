{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"colab":{"provenance":[],"gpuType":"T4"},"accelerator":"GPU","kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[],"dockerImageVersionId":30787,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import torch\nfrom torch import nn\nfrom torch.nn import functional as F\nfrom torchvision import datasets, transforms,models\nfrom torch.utils.data import DataLoader, Subset\nfrom collections import OrderedDict\nfrom copy import deepcopy\nfrom matplotlib import pyplot as plt\nfrom PIL import Image\nimport numpy as n\nimport torch.optim as optim\nimport random\nfrom tqdm import tqdm\nimport seaborn as sns\nimport os","metadata":{"id":"hQ7QKqMN4khF","trusted":true,"execution":{"iopub.status.busy":"2024-12-13T14:23:46.629504Z","iopub.execute_input":"2024-12-13T14:23:46.630166Z","iopub.status.idle":"2024-12-13T14:23:52.785793Z","shell.execute_reply.started":"2024-12-13T14:23:46.630124Z","shell.execute_reply":"2024-12-13T14:23:52.784854Z"}},"outputs":[],"execution_count":1},{"cell_type":"code","source":"transform = transforms.Compose([\n    transforms.ToTensor(),\n    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n])\n\ntrain_dataset = datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)\n\n# Function to filter dataset\ndef get_filtered_dataset(dataset, excluded_class):\n    indices = [i for i, (_, label) in enumerate(dataset) if label != excluded_class]\n    return Subset(dataset, indices)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-13T14:23:52.787339Z","iopub.execute_input":"2024-12-13T14:23:52.787732Z","iopub.status.idle":"2024-12-13T14:23:57.436897Z","shell.execute_reply.started":"2024-12-13T14:23:52.787706Z","shell.execute_reply":"2024-12-13T14:23:57.435963Z"}},"outputs":[{"name":"stdout","text":"Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./data/cifar-10-python.tar.gz\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 170498071/170498071 [00:01<00:00, 87973466.91it/s]\n","output_type":"stream"},{"name":"stdout","text":"Extracting ./data/cifar-10-python.tar.gz to ./data\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"from torch.utils.data import Dataset\n\nclass RemappedDataset(Dataset):\n    def __init__(self, subset, excluded_class):\n        self.subset = subset\n        self.excluded_class = excluded_class\n        self.label_map = self._create_label_map()\n\n    def _create_label_map(self):\n        \"\"\"Create a mapping from original labels to new labels.\"\"\"\n        labels = [label for _, label in self.subset]\n        unique_labels = sorted(set(labels) - {self.excluded_class})\n        return {original: new for new, original in enumerate(unique_labels)}\n\n    def __len__(self):\n        return len(self.subset)\n\n    def __getitem__(self, idx):\n        data, label = self.subset[idx]\n        return data, self.label_map[label]\n\n# Update filtered dataset creation\ndef get_filtered_and_remapped_dataset(dataset, excluded_class):\n    indices = [i for i, (_, label) in enumerate(dataset) if label != excluded_class]\n    filtered_subset = Subset(dataset, indices)\n    return RemappedDataset(filtered_subset, excluded_class)\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-13T14:23:57.438329Z","iopub.execute_input":"2024-12-13T14:23:57.438698Z","iopub.status.idle":"2024-12-13T14:23:57.446280Z","shell.execute_reply.started":"2024-12-13T14:23:57.438661Z","shell.execute_reply":"2024-12-13T14:23:57.445374Z"}},"outputs":[],"execution_count":3},{"cell_type":"code","source":"def train_resnet(model, train_loader, epochs=10, device=\"cpu\"):\n    model.to(device)\n    optimizer = optim.Adam(model.parameters(), lr=0.001)\n    criterion = nn.CrossEntropyLoss()\n    model.train()\n\n    for epoch in range(epochs):\n        running_loss = 0.0\n        for inputs, labels in train_loader:\n            inputs, labels = inputs.to(device), labels.to(device)\n            optimizer.zero_grad()\n            outputs = model(inputs)\n            loss = criterion(outputs, labels)\n            loss.backward()\n            optimizer.step()\n            running_loss += loss.item()\n        print(f\"Epoch {epoch + 1}/{epochs}, Loss: {running_loss:.4f}\")\n    \n    return model\n\n# Extract and stack weight matrices\n\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n\n# ResNet18 on all classes\nmodel_all = models.resnet18(num_classes=10)  # Adjust for CIFAR-10\ntrain_loader_all = DataLoader(train_dataset, batch_size=64, shuffle=True)\ntrained_model_all = train_resnet(model_all, train_loader_all, device=device)\n\nfiltered_dataset = get_filtered_and_remapped_dataset(train_dataset, excluded_class=0)\ntrain_loader_filtered = DataLoader(filtered_dataset, batch_size=64, shuffle=True)\nmodel_filtered = models.resnet18(num_classes=9)  # Adjust for 9 classes\ntrained_model_filtered = train_resnet(model_filtered, train_loader_filtered, device=device)\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-13T14:34:43.766939Z","iopub.execute_input":"2024-12-13T14:34:43.767345Z","iopub.status.idle":"2024-12-13T14:43:38.592209Z","shell.execute_reply.started":"2024-12-13T14:34:43.767313Z","shell.execute_reply":"2024-12-13T14:43:38.591061Z"}},"outputs":[{"name":"stdout","text":"Epoch 1/10, Loss: 1057.3900\nEpoch 2/10, Loss: 755.3089\nEpoch 3/10, Loss: 629.5726\nEpoch 4/10, Loss: 532.3601\nEpoch 5/10, Loss: 452.4486\nEpoch 6/10, Loss: 384.9198\nEpoch 7/10, Loss: 316.1419\nEpoch 8/10, Loss: 256.9689\nEpoch 9/10, Loss: 207.9186\nEpoch 10/10, Loss: 166.8531\nEpoch 1/10, Loss: 928.6663\nEpoch 2/10, Loss: 678.3267\nEpoch 3/10, Loss: 561.7547\nEpoch 4/10, Loss: 481.9064\nEpoch 5/10, Loss: 415.5102\nEpoch 6/10, Loss: 347.0804\nEpoch 7/10, Loss: 294.4699\nEpoch 8/10, Loss: 244.5737\nEpoch 9/10, Loss: 207.9106\nEpoch 10/10, Loss: 156.4852\n","output_type":"stream"}],"execution_count":12},{"cell_type":"code","source":"# Stack weight matrices\ndef get_activations(model):\n    act = []\n    for name, param in model.named_parameters():\n        if 'weight' in name and len(param.shape)<=2:\n            act.append(param.clone().detach().cpu().numpy())\n        \n    return act \n\nweights_all = get_activations(trained_model_all)\nweights_filtered = get_activations(trained_model_filtered)\n\n# Stack the weights from both models\n#stacked_weights = [torch.stack([w_all, w_filtered]) for w_all, w_filtered in zip(weights_all, weights_filtered)]\n\n# Print shapes of stacked weights\nfor i, weights in enumerate(weights_all):\n    print(f\"Layer {i + 1}, Stacked Weight Shape: {weights.shape}\")\n\nfor i, weights in enumerate(weights_filtered):\n    print(f\"Layer {i + 1}, Stacked Weight Shape: {weights.shape}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-13T14:45:44.578488Z","iopub.execute_input":"2024-12-13T14:45:44.578826Z","iopub.status.idle":"2024-12-13T14:45:44.590361Z","shell.execute_reply.started":"2024-12-13T14:45:44.578800Z","shell.execute_reply":"2024-12-13T14:45:44.589556Z"}},"outputs":[{"name":"stdout","text":"Layer 1, Stacked Weight Shape: (64,)\nLayer 2, Stacked Weight Shape: (64,)\nLayer 3, Stacked Weight Shape: (64,)\nLayer 4, Stacked Weight Shape: (64,)\nLayer 5, Stacked Weight Shape: (64,)\nLayer 6, Stacked Weight Shape: (128,)\nLayer 7, Stacked Weight Shape: (128,)\nLayer 8, Stacked Weight Shape: (128,)\nLayer 9, Stacked Weight Shape: (128,)\nLayer 10, Stacked Weight Shape: (128,)\nLayer 11, Stacked Weight Shape: (256,)\nLayer 12, Stacked Weight Shape: (256,)\nLayer 13, Stacked Weight Shape: (256,)\nLayer 14, Stacked Weight Shape: (256,)\nLayer 15, Stacked Weight Shape: (256,)\nLayer 16, Stacked Weight Shape: (512,)\nLayer 17, Stacked Weight Shape: (512,)\nLayer 18, Stacked Weight Shape: (512,)\nLayer 19, Stacked Weight Shape: (512,)\nLayer 20, Stacked Weight Shape: (512,)\nLayer 21, Stacked Weight Shape: (10, 512)\nLayer 1, Stacked Weight Shape: (64,)\nLayer 2, Stacked Weight Shape: (64,)\nLayer 3, Stacked Weight Shape: (64,)\nLayer 4, Stacked Weight Shape: (64,)\nLayer 5, Stacked Weight Shape: (64,)\nLayer 6, Stacked Weight Shape: (128,)\nLayer 7, Stacked Weight Shape: (128,)\nLayer 8, Stacked Weight Shape: (128,)\nLayer 9, Stacked Weight Shape: (128,)\nLayer 10, Stacked Weight Shape: (128,)\nLayer 11, Stacked Weight Shape: (256,)\nLayer 12, Stacked Weight Shape: (256,)\nLayer 13, Stacked Weight Shape: (256,)\nLayer 14, Stacked Weight Shape: (256,)\nLayer 15, Stacked Weight Shape: (256,)\nLayer 16, Stacked Weight Shape: (512,)\nLayer 17, Stacked Weight Shape: (512,)\nLayer 18, Stacked Weight Shape: (512,)\nLayer 19, Stacked Weight Shape: (512,)\nLayer 20, Stacked Weight Shape: (512,)\nLayer 21, Stacked Weight Shape: (9, 512)\n","output_type":"stream"}],"execution_count":14},{"cell_type":"code","source":"print(weights_all[20])\nprint(weights_all[20].shape)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-13T14:45:51.010611Z","iopub.execute_input":"2024-12-13T14:45:51.011342Z","iopub.status.idle":"2024-12-13T14:45:51.016640Z","shell.execute_reply.started":"2024-12-13T14:45:51.011307Z","shell.execute_reply":"2024-12-13T14:45:51.015592Z"}},"outputs":[{"name":"stdout","text":"[[ 0.03725792  0.05180766 -0.00685087 ...  0.06033065 -0.01167728\n   0.05603654]\n [-0.01203199  0.08099366  0.07495472 ... -0.00507944 -0.04612529\n   0.02951003]\n [-0.02401016 -0.07304101 -0.01087607 ... -0.10882819  0.06561099\n   0.01976266]\n ...\n [-0.01675912 -0.10471803  0.00036213 ... -0.01323636 -0.01850379\n  -0.11095271]\n [-0.06432104  0.07729784 -0.00498304 ...  0.03404438  0.00969019\n  -0.0333106 ]\n [ 0.04058057  0.07919856  0.03500961 ...  0.04702904 -0.04107332\n  -0.04466205]]\n(10, 512)\n","output_type":"stream"}],"execution_count":15},{"cell_type":"code","source":"print(weights_filtered[20])\nweights_filtered[20].shape","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-13T14:45:54.289371Z","iopub.execute_input":"2024-12-13T14:45:54.289698Z","iopub.status.idle":"2024-12-13T14:45:54.297135Z","shell.execute_reply.started":"2024-12-13T14:45:54.289669Z","shell.execute_reply":"2024-12-13T14:45:54.296329Z"}},"outputs":[{"name":"stdout","text":"[[-0.00465177  0.00755466 -0.07922242 ...  0.02758088 -0.00133221\n   0.01430744]\n [-0.03925995  0.01276677 -0.16534159 ... -0.01652874 -0.04668239\n  -0.01674438]\n [-0.02084461  0.01710148  0.07989341 ... -0.03581994 -0.05898105\n  -0.00789738]\n ...\n [-0.0325629  -0.00528347  0.01940736 ... -0.00742166  0.01343936\n  -0.01556363]\n [ 0.02454785 -0.0184033  -0.02665224 ...  0.04552277  0.03269222\n   0.02953606]\n [-0.00875199  0.00861988 -0.00737541 ...  0.04830784  0.01780627\n   0.01181417]]\n","output_type":"stream"},{"execution_count":16,"output_type":"execute_result","data":{"text/plain":"(9, 512)"},"metadata":{}}],"execution_count":16},{"cell_type":"code","source":"\nX = torch.tensor(weights_all[20])\nX = X[1:]\nY = torch.tensor(weights_filtered[20])\nmax_diff = torch.max(torch.abs(X - Y))\nprint(max_diff)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-13T14:46:09.435487Z","iopub.execute_input":"2024-12-13T14:46:09.435849Z","iopub.status.idle":"2024-12-13T14:46:09.442752Z","shell.execute_reply.started":"2024-12-13T14:46:09.435815Z","shell.execute_reply":"2024-12-13T14:46:09.441916Z"}},"outputs":[{"name":"stdout","text":"tensor(0.3266)\n","output_type":"stream"}],"execution_count":19}]}